{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moderate Image Using Azure Content Safety API\n",
    "\n",
    "Start by installing the packages that will be required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the packages\n",
    "%pip install requests\n",
    "%pip install azure-ai-contentsafety\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages\n",
    "\n",
    "Next, you'll import all the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.contentsafety import ContentSafetyClient\n",
    "from azure.ai.contentsafety.models import ImageCategory\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.ai.contentsafety.models import AnalyzeImageOptions, ImageData, AnalyzeImageOutputType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Content Safety Client\n",
    "\n",
    "You will create content safety `client` in this step which will be used to pass API requests to Azure servers for moderations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your Azure Safety API key and endpoint\n",
    "load_dotenv()\n",
    "\n",
    "key = os.environ[\"CONTENT_SAFETY_KEY\"]\n",
    "endpoint = os.environ[\"CONTENT_SAFETY_ENDPOINT\"]\n",
    "\n",
    "# Create a Content Safety client\n",
    "client = ContentSafetyClient(endpoint, AzureKeyCredential(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moderate Image\n",
    "\n",
    "Implement the `moderate_image` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moderate_image(image_data):\n",
    "    # Construct a request\n",
    "    request = AnalyzeImageOptions(image=ImageData(content=image_data))\n",
    "\n",
    "    # Analyze image\n",
    "    try:\n",
    "        response = client.analyze_image(request)\n",
    "    except HttpResponseError as e:\n",
    "        print(\"Analyze image failed.\")\n",
    "        if e.error:\n",
    "            print(f\"Error code: {e.error.code}\")\n",
    "            print(f\"Error message: {e.error.message}\")\n",
    "            raise\n",
    "        print(e)\n",
    "        raise\n",
    "\n",
    "    # Extract results\n",
    "    categories = {\n",
    "        ImageCategory.HATE: None,\n",
    "        ImageCategory.SELF_HARM: None,\n",
    "        ImageCategory.SEXUAL: None,\n",
    "        ImageCategory.VIOLENCE: None\n",
    "    }\n",
    "\n",
    "    for item in response.categories_analysis:\n",
    "        if item.category in categories:\n",
    "            categories[item.category] = item\n",
    "\n",
    "    hate_result = categories[ImageCategory.HATE]\n",
    "    self_harm_result = categories[ImageCategory.SELF_HARM]\n",
    "    sexual_result = categories[ImageCategory.SEXUAL]\n",
    "    violence_result = categories[ImageCategory.VIOLENCE]\n",
    "\n",
    "    # Check for inappropriate content\n",
    "    violations = []\n",
    "    if hate_result and hate_result.severity > 2:\n",
    "        violations.append(\"hate speech\")\n",
    "    if self_harm_result and self_harm_result.severity > 3:\n",
    "        violations.append(\"self-harm references\")\n",
    "    if sexual_result and sexual_result.severity > 0:\n",
    "        violations.append(\"sexual references\")\n",
    "    if violence_result and violence_result.severity > 2:\n",
    "        violations.append(\"violent references\")\n",
    "\n",
    "    if violations:\n",
    "        return f\"Your shared image contains {', '.join(violations)} that violate our community guidelines. Please modify your image to adhere to community guidelines.\"\n",
    "\n",
    "    # If content is appropriate\n",
    "    return \"Post successful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../sample-data/test-images/pexels-ash-craig-122861-376464.jpg', 'rb') as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "moderation_response = moderate_image(image_data)\n",
    "print(moderation_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
